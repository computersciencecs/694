{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c53b5-8be6-4469-a6ac-c9fa21c7b9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5bb42-f06b-4af3-a496-9a86c6f93acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "input_file = \"inference.txt\"\n",
    "output_file = \"1.txt\"\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    match = re.search(r'Output:\\s*(.*?)\\s*Explanation', line)\n",
    "    if match:\n",
    "        score = match.group(1).strip()\n",
    "        scores.append(score)\n",
    "    else:\n",
    "        scores.append(\"\")  \n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(scores))\n",
    "\n",
    "print(f\"✅  completed, results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0622c41f-0ede-4e48-8c88-6cb49ae84a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = \"1.txt\"\n",
    "output_file = \"filled_1.txt\"\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "processed_lines = [\"0\" if line.strip() == \"\" else line.strip() for line in lines]\n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(processed_lines) + \"\\n\") \n",
    "\n",
    "print(f\"✅ Processing completed, results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f13560-fd43-4c8b-8fda-4fbf1f06594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "input_file = \"filled_1.txt\"\n",
    "output_file = \"processed_filled_1.txt\"\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "replacements = {\n",
    "    \"```3;```###\": \"3\",\n",
    "    \"1```###\": \"1\",\n",
    "    \"```4```###\": \"4\",\n",
    "    \"5###\": \"5\",\n",
    "    \"```4;```###\": \"4\",\n",
    "    \"4###\": \"4\",\n",
    "    \"4```###\": \"4\",\n",
    "    \"```5;```###\": \"5\",\n",
    "    \"5```###\": \"5\",\n",
    "    \"```4```###\": \"4\",\n",
    "    \"```5```###\": \"5\",\n",
    "    \"444Sample\": \"4\",\n",
    "    \"4.0\": \"4\",\n",
    "    \"4Sample\": \"4\",\n",
    "    \"10.00.00.0\": \"0\",\n",
    "    \"1111\": \"1\",\n",
    "    \"1 1 1 1 1 1 1 1\": \"1\",\n",
    "    \"1 4 4 4 4\": \"4\",\n",
    "    \"1 4 4 4 41 4 4 4 41 4 4 4 4\": \"4\",\n",
    "    \"1 4 4 4 4 4 41 4 4 4 4 4 41 4 4 4 4 4 4\": \"4\",\n",
    "    \"1 1 1 1 1 1 1\": \"1\",\n",
    "    \"1 1 1 1 1 1\": \"1\",\n",
    "    \"1 1 1 1 1\": \"1\",\n",
    "    \"1 4 3 5\": \"3\",\n",
    "    \"10.020.030.0\": \"0\",\n",
    "    \"10.010.010.0\": \"0\",\n",
    "    \"123\": \"2\",\n",
    "    \"1 1 1 1 1 1 1 1 1 1\": \"1\",\n",
    "    \"```0.0```###\": \"0\",\n",
    "    \"```1```###\": \"1\",\n",
    "    \"110.0\": \"0\",\n",
    "    \"5.05.05.0\": \"5\",\n",
    "    \"5.0\": \"5\",\n",
    "    \"0.0\": \"0\",\n",
    "    \"111\": \"1\",\n",
    "    \"0.00.00.0\": \"0\",\n",
    "    \"4.04.04.0\": \"4\",\n",
    "    \"444\": \"4\",\n",
    "    \"1.01.01.0\": \"1\",\n",
    "    \"555\": \"5\",\n",
    "    \"0.0###\": \"0\",\n",
    "    \"4.0###\": \"4\",\n",
    "    \"5.0###\": \"5\"\n",
    "}\n",
    "\n",
    "\n",
    "processed_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip() \n",
    "    for pattern, replacement in replacements.items():\n",
    "        if re.fullmatch(pattern, line): \n",
    "            line = replacement\n",
    "            break  \n",
    "    processed_lines.append(line)\n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(processed_lines) + \"\\n\")  \n",
    "\n",
    "print(f\"✅ Processing completed, results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67881e3-fd4a-46f1-9ae7-1c6fb7201029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "jsonl_file = \"cleaned.jsonl\"\n",
    "scores_file = \"processed_filled_1.txt\"\n",
    "output_csv = \"movies_with_scores.csv\"\n",
    "\n",
    "\n",
    "with open(scores_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    scores = [line.strip() for line in file.readlines()]\n",
    "\n",
    "\n",
    "movies = []\n",
    "with open(jsonl_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        inst = data.get(\"inst\", \"\")\n",
    "\n",
    "        \n",
    "        match = re.search(r'the target music\\s*\"(.*?)\"\\s*with the user', inst)\n",
    "        if match:\n",
    "            movie_name = match.group(1)\n",
    "        else:\n",
    "            movie_name = \"Unknown\"\n",
    "\n",
    "        movies.append(movie_name)\n",
    "\n",
    "\n",
    "if len(movies) != len(scores):\n",
    "    print(\"⚠️ Warning: Number of movies does not match number of ratings！\")\n",
    "else:\n",
    "    print(\"✅ Data matching is successful, start writingCSV...\")\n",
    "\n",
    "# 写入 CSV 文件\n",
    "with open(output_csv, \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Movie\", \"Score\"])  # 写入表头\n",
    "    for movie, score in zip(movies, scores):\n",
    "        writer.writerow([movie, score])\n",
    "\n",
    "print(f\"✅ Processing completed, results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cead07b-d2ee-475b-a8fd-06070b457f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_csv = \"movies_with_scores.csv\"\n",
    "output_csv = \"movies_recommendations.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "\n",
    "movies = df.iloc[:, 0].tolist()  \n",
    "scores = df.iloc[:, 1].astype(float).tolist()  \n",
    "\n",
    "\n",
    "alpha1 = 0.05\n",
    "\n",
    "\n",
    "num_movies = len(movies)\n",
    "group_size = 10  \n",
    "recommendations = []\n",
    "\n",
    "for i in range(0, num_movies, group_size):\n",
    "    movie_group = movies[i:i+group_size] \n",
    "    score_group = scores[i:i+group_size]  \n",
    "\n",
    "    \n",
    "    if len(movie_group) < group_size:\n",
    "        continue\n",
    "\n",
    "   \n",
    "    adjusted_scores = [score + alpha1 * (group_size - rank) for rank, score in enumerate(score_group)]\n",
    "\n",
    "    \n",
    "    sorted_movies = [movie for _, movie in sorted(zip(adjusted_scores, movie_group), reverse=True)]\n",
    "\n",
    "   \n",
    "    recommendations.append([len(recommendations) + 1] + sorted_movies[:5])\n",
    "\n",
    "\n",
    "columns = [\"Line Number\", \"Movie 1\", \"Movie 2\", \"Movie 3\", \"Movie 4\", \"Movie 5\"]\n",
    "df_output = pd.DataFrame(recommendations, columns=columns)\n",
    "df_output.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✅ Processing completed, results saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b9d82c-8649-4287-9d1a-ef53fe8e94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_files(user_item_file, movie_info_file, output_file):\n",
    "    \n",
    "    user_item_df = pd.read_csv(user_item_file, header=None, names=['user_id', 'item_id'])\n",
    "    \n",
    "    \n",
    "    movie_info_df = pd.read_csv(movie_info_file, sep='|', header=None, names=['item_id', 'movie_name'],engine='python', encoding='latin-1')\n",
    "\n",
    "    \n",
    "    \n",
    "    merged_df = pd.merge(user_item_df, movie_info_df[['item_id', 'movie_name']], on='item_id', how='left')\n",
    "    \n",
    "    \n",
    "    merged_df.insert(0, 'index', range(1, len(merged_df) + 1))\n",
    "    \n",
    "   \n",
    "    final_df = merged_df[['index', 'item_id', 'movie_name']]\n",
    "    \n",
    "    \n",
    "    final_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "# Usage\n",
    "merge_files('XSimGCLgt_save_dict1.csv', 'itemnew-processed.csv', 'gt-match-output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41a89d3-16ed-49a7-8b2b-5b10a27305b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: merged_with_movie_name.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "movies_recommendations = pd.read_csv('movies_recommendations.csv')\n",
    "match_output = pd.read_csv('gt-match-output.csv')\n",
    "\n",
    "# Merge the files based on the 'Line Number' from movies_recommendations and 'index' from match_output\n",
    "merged_df = pd.merge(movies_recommendations, match_output[['index', 'movie_name']], how='left', left_on='Line Number', right_on='index')\n",
    "\n",
    "# Drop the extra 'index' column after the merge\n",
    "merged_df = merged_df.drop(columns=['index'])\n",
    "\n",
    "# Save the merged result to a new CSV file\n",
    "output_file = 'merged_with_movie_name.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4592747b-29bc-4cbf-9f24-f04549444be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: merged_with_match_column.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged CSV file\n",
    "merged_df = pd.read_csv('merged_with_movie_name.csv')\n",
    "\n",
    "# Function to check if the movie_name matches any of Movie1 to Movie5\n",
    "def check_match(row):\n",
    "    for i in range(1, 6):\n",
    "        if row['movie_name'] == row[f'Movie {i}']:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "# Apply the check_match function to each row and create a new column for the result\n",
    "merged_df['Match'] = merged_df.apply(check_match, axis=1)\n",
    "\n",
    "# Save the updated dataframe with the new column\n",
    "output_file_with_match = 'merged_with_match_column.csv'\n",
    "merged_df.to_csv(output_file_with_match, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file_with_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050974f-a2b9-42c4-b29f-3d6171998e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged CSV file with the match column\n",
    "df = pd.read_csv('merged_with_match_column.csv')\n",
    "\n",
    "# Function to calculate Hit@n\n",
    "def calculate_hit(df, n):\n",
    "    return df['Match'].apply(lambda x: 1 if 0 < x <= n else 0).mean()\n",
    "\n",
    "# Function to calculate DCG@n and NDCG@n for each row\n",
    "def calculate_dcg(row, n):\n",
    "    match = row['Match']\n",
    "    if 0 < match <= n:  # if there's a match in the top n\n",
    "        return 1 / np.log2(match + 1)\n",
    "    return 0\n",
    "\n",
    "# Function to calculate NDCG@n\n",
    "def calculate_ndcg(df, n):\n",
    "    # Calculate DCG@n for each row\n",
    "    df[f'DCG@{n}'] = df.apply(lambda row: calculate_dcg(row, n), axis=1)\n",
    "    # Ideal DCG@n (IDCG@n) is always 1, since the best match is in the first position\n",
    "    idcg = 1 / np.log2(2)\n",
    "    # Calculate NDCG@n for each row\n",
    "    df[f'NDCG@{n}'] = df[f'DCG@{n}'] / idcg\n",
    "    return df[f'NDCG@{n}'].mean()\n",
    "\n",
    "# Calculate Hit@3 and NDCG@3\n",
    "hit_at_3 = calculate_hit(df, 3)\n",
    "ndcg_at_3 = calculate_ndcg(df, 3)\n",
    "\n",
    "# Calculate Hit@5 and NDCG@5\n",
    "hit_at_5 = calculate_hit(df, 5)\n",
    "ndcg_at_5 = calculate_ndcg(df, 5)\n",
    "\n",
    "# Scale factor508 / 6035   127 / 942  103 / 1162\n",
    "scale_factor = 120/ 1162\n",
    "\n",
    "# Scaled results\n",
    "scaled_hit_at_3 = hit_at_3 * scale_factor\n",
    "scaled_ndcg_at_3 = ndcg_at_3 * scale_factor\n",
    "scaled_hit_at_5 = hit_at_5 * scale_factor\n",
    "scaled_ndcg_at_5 = ndcg_at_5 * scale_factor\n",
    "\n",
    "# Output the results\n",
    "print(f\"Hit@3: {hit_at_3}\")\n",
    "print(f\"NDCG@3: {ndcg_at_3}\")\n",
    "print(f\"Hit@5: {hit_at_5}\")\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")\n",
    "\n",
    "print(\"\\n### Scaled Results (Multiplied by 120/ 1162) ###\")\n",
    "print(f\"Scaled Hit@3: {scaled_hit_at_3}\")\n",
    "print(f\"Scaled NDCG@3: {scaled_ndcg_at_3}\")\n",
    "print(f\"Scaled Hit@5: {scaled_hit_at_5}\")\n",
    "print(f\"Scaled NDCG@5: {scaled_ndcg_at_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c89f92-cfed-45c8-8932-524be30ac060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
