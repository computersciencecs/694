{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72be58-ad1b-4e7d-a556-0158d195bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "input_file = \"inference.txt\"\n",
    "output_file = \"cleaned_pairresult.txt\"\n",
    "\n",
    "\n",
    "cleaned_lines = []\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    match = re.search(r'Output:\\s*(.*?)\\s*\\.```', line)\n",
    "    if match:\n",
    "        extracted_text = match.group(1).strip()\n",
    "        cleaned_lines.append(extracted_text)\n",
    "    else:\n",
    "        cleaned_lines.append(random.choice([\"Yes\", \"No\"]))\n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(cleaned_lines))\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09331e-2e75-4dfa-b94c-234685b241e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "input_file = \"list-100k-mf.txt\"\n",
    "output_file = \"cleaned_pairresult.txt\"\n",
    "\n",
    "\n",
    "cleaned_lines = []\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "   \n",
    "    match = re.search(r'Output:\\s*(.*?)\\s*\\.```', line)\n",
    "    if match:\n",
    "        extracted_text = match.group(1).strip()\n",
    "        cleaned_lines.append(extracted_text)\n",
    "    else:\n",
    "        cleaned_lines.append(random.choice([\"Yes\", \"No\"]))  \n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(cleaned_lines))\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf71ae-2af5-42e3-8f8e-713372480347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "input_file = \"cleaned_pairresult.txt\"\n",
    "output_file = \"cleaned_pairresult1.txt\"\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "replacements = {\n",
    "    \"```Yes\": \"Yes\",\n",
    "    \"```No\": \"No\"\n",
    "}\n",
    "\n",
    "\n",
    "processed_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip() \n",
    "    for pattern, replacement in replacements.items():\n",
    "        if re.fullmatch(pattern, line): \n",
    "            line = replacement\n",
    "            break  \n",
    "    processed_lines.append(line)\n",
    "\n",
    "# 写入新文件\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\".join(processed_lines) + \"\\n\")  \n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75419b4-6c33-4a4b-928d-679b34e88571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "\n",
    "pairalltest_file = \"pairall.jsonl\"\n",
    "cleaned_results_file = \"cleaned_pairresult1.txt\"\n",
    "output_csv_file = \"pair_results.csv\"\n",
    "\n",
    "\n",
    "with open(pairalltest_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "total_lines = len(lines)\n",
    "half_lines = total_lines // 2 \n",
    "\n",
    "\n",
    "with open(cleaned_results_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    cleaned_results = f.readlines()\n",
    "\n",
    "\n",
    "pattern = r'Question: Would the user prefer \"(.*?)\" over \"(.*?)\"\\?Hint: Another'\n",
    "\n",
    "\n",
    "data_rows = []\n",
    "for idx in range(half_lines):\n",
    "    json_line = json.loads(lines[idx])  \n",
    "    text = json_line[\"inst\"]  \n",
    "\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        movie1 = match.group(1)\n",
    "        movie2 = match.group(2)\n",
    "    else:\n",
    "        movie1 = \"\"\n",
    "        movie2 = \"\"\n",
    "\n",
    " \n",
    "    result_forward = cleaned_results[idx].strip() \n",
    "    result_reverse = cleaned_results[idx + half_lines].strip() \n",
    "\n",
    "    data_rows.append([idx + 1, movie1, movie2, result_forward, result_reverse])\n",
    "\n",
    "\n",
    "with open(output_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Line Number\", \"Movie 1\", \"Movie 2\", \"Result Forward\", \"Result Reverse\"])  \n",
    "    writer.writerows(data_rows) \n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275f06b-1a89-4676-8292-0533eda9e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_file = \"pair_results.csv\" \n",
    "output_file = \"pair_results_with_scores.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "INITIAL_SCORES_MOVIE1 = [10, 9, 8, 7, 6] \n",
    "INITIAL_SCORES_MOVIE2 = [5, 4, 3, 2, 1]  \n",
    "BOOST_SCORE = 200  \n",
    "\n",
    "\n",
    "results = []\n",
    "for i in range(0, len(df), 5):\n",
    "    group = df.iloc[i:i+5].copy() \n",
    "    if len(group) < 5:\n",
    "        continue  \n",
    "    \n",
    "    \n",
    "    scores_forward = {}\n",
    "    scores_reverse = {}\n",
    "\n",
    "    for idx, row in enumerate(group.iterrows()):\n",
    "        movie1, movie2 = row[1][\"Movie 1\"], row[1][\"Movie 2\"]\n",
    "        scores_forward[movie1] = INITIAL_SCORES_MOVIE1[idx]\n",
    "        scores_forward[movie2] = INITIAL_SCORES_MOVIE2[idx]\n",
    "        scores_reverse[movie1] = INITIAL_SCORES_MOVIE1[idx]\n",
    "        scores_reverse[movie2] = INITIAL_SCORES_MOVIE2[idx]\n",
    "\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        movie1, movie2, result_forward, result_reverse = row[\"Movie 1\"], row[\"Movie 2\"], row[\"Result Forward\"], row[\"Result Reverse\"]\n",
    "        \n",
    "        \n",
    "        if result_forward == \"Yes\":\n",
    "            scores_forward[movie1] += BOOST_SCORE \n",
    "        elif result_forward == \"No\":\n",
    "            scores_forward[movie2] += BOOST_SCORE \n",
    "\n",
    "        \n",
    "        if result_forward == \"Yes\" and result_reverse == \"Yes\":\n",
    "            \n",
    "            scores_reverse[movie1] += BOOST_SCORE / 2\n",
    "            scores_reverse[movie2] += BOOST_SCORE / 2\n",
    "        elif result_forward == \"No\" and result_reverse == \"No\":\n",
    "            \n",
    "            scores_reverse[movie1] += BOOST_SCORE / 2\n",
    "            scores_reverse[movie2] += BOOST_SCORE / 2\n",
    "        elif result_forward == \"Yes\" and result_reverse == \"No\":\n",
    "            \n",
    "            scores_reverse[movie1] += BOOST_SCORE\n",
    "        elif result_forward == \"No\" and result_reverse == \"Yes\":\n",
    "            \n",
    "            scores_reverse[movie2] += BOOST_SCORE\n",
    "\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        movie1, movie2 = row[\"Movie 1\"], row[\"Movie 2\"]\n",
    "        results.append([\n",
    "            row[\"Line Number\"],\n",
    "            movie1, movie2,\n",
    "            row[\"Result Forward\"], row[\"Result Reverse\"],\n",
    "            scores_forward[movie1], scores_forward[movie2],\n",
    "            scores_reverse[movie1], scores_reverse[movie2]\n",
    "        ])\n",
    "\n",
    "\n",
    "output_df = pd.DataFrame(results, columns=[\n",
    "    \"Line Number\", \"Movie 1\", \"Movie 2\", \"Result Forward\", \"Result Reverse\",\n",
    "    \"Movie 1 Forward Score\", \"Movie 2 Forward Score\",\n",
    "    \"Movie 1 Reverse Score\", \"Movie 2 Reverse Score\"\n",
    "])\n",
    "\n",
    "\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75dc3f-4c9c-4f69-86b4-eaf686be9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_file = \"pair_results_with_scores.csv\"\n",
    "output_file = \"pair_results_with_total_scores.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "df[\"Movie 1 Total Score\"] = df[\"Movie 1 Forward Score\"] + df[\"Movie 1 Reverse Score\"]\n",
    "\n",
    "\n",
    "df[\"Movie 2 Total Score\"] = df[\"Movie 2 Forward Score\"] + df[\"Movie 2 Reverse Score\"]\n",
    "\n",
    "\n",
    "same_check_results = []\n",
    "for i in range(0, len(df), 5): \n",
    "    group = df.iloc[i:i+5].copy()  \n",
    "    \n",
    "    \n",
    "    total_scores = group[\"Movie 1 Total Score\"].tolist() + group[\"Movie 2 Total Score\"].tolist()\n",
    "\n",
    "   \n",
    "    if len(total_scores) != len(set(total_scores)): \n",
    "        same_check_results.extend([\"same\"] * 5)  \n",
    "    else:\n",
    "        same_check_results.extend([\"no\"] * 5)  \n",
    "\n",
    "\n",
    "df[\"Same Check\"] = same_check_results\n",
    "\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472a22f-9834-40d3-8a3b-470933adbf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_file = \"pair_results_with_scores.csv\"\n",
    "output_file = \"pair_results_with_total_scores.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "df[\"Movie 1 Total Score\"] = df[\"Movie 1 Forward Score\"] + df[\"Movie 1 Reverse Score\"]\n",
    "\n",
    "\n",
    "df[\"Movie 2 Total Score\"] = df[\"Movie 2 Forward Score\"] + df[\"Movie 2 Reverse Score\"]\n",
    "\n",
    "\n",
    "same_check_results = []\n",
    "for i in range(0, len(df), 5): \n",
    "    group = df.iloc[i:i+5].copy()  \n",
    "    \n",
    "    \n",
    "    total_scores = group[\"Movie 1 Total Score\"].tolist() + group[\"Movie 2 Total Score\"].tolist()\n",
    "\n",
    "  \n",
    "    if len(total_scores) != len(set(total_scores)):  \n",
    "        same_check_results.extend([\"same\"] * 5)  \n",
    "    else:\n",
    "        same_check_results.extend([\"no\"] * 5)  \n",
    "\n",
    "\n",
    "df[\"Same Check\"] = same_check_results\n",
    "\n",
    "\n",
    "same_count = same_check_results.count(\"same\")\n",
    "\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95373b13-8ce5-4729-8116-b76a679c61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "input_file = \"pair_results_with_total_scores.csv\"\n",
    "output_file = \"movies_recommendations.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "recommendations = []\n",
    "for i in range(0, len(df), 5):\n",
    "    group = df.iloc[i:i+5].copy()\n",
    "\n",
    "    \n",
    "    movie_scores = {}\n",
    "    for _, row in group.iterrows():\n",
    "        movie_scores[row[\"Movie 1\"]] = row[\"Movie 1 Total Score\"]\n",
    "        movie_scores[row[\"Movie 2\"]] = row[\"Movie 2 Total Score\"]\n",
    "\n",
    "    \n",
    "    sorted_movies = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    \n",
    "    grouped_movies = {}\n",
    "    for movie, score in sorted_movies:\n",
    "        grouped_movies.setdefault(score, []).append(movie)\n",
    "\n",
    "    \n",
    "    for score in grouped_movies:\n",
    "        random.shuffle(grouped_movies[score])\n",
    "\n",
    "    \n",
    "    final_sorted_movies = []\n",
    "    for score in sorted(grouped_movies.keys(), reverse=True):\n",
    "        final_sorted_movies.extend(grouped_movies[score])\n",
    "\n",
    "    \n",
    "    top_5_movies = final_sorted_movies[:5]\n",
    "\n",
    "    \n",
    "    recommendations.append([i // 5 + 1] + top_5_movies) \n",
    "\n",
    "\n",
    "output_df = pd.DataFrame(recommendations, columns=[\"Line Number\", \"Movie 1\", \"Movie 2\", \"Movie 3\", \"Movie 4\", \"Movie 5\"])\n",
    "\n",
    "\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Cleaning completed, results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f06a4dd-b318-4585-9fbf-36056996e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_files(user_item_file, movie_info_file, output_file):\n",
    "    \n",
    "    user_item_df = pd.read_csv(user_item_file, header=None, names=['user_id', 'item_id'])\n",
    "    \n",
    "    \n",
    "    movie_info_df = pd.read_csv(movie_info_file, sep='|', header=None, names=['item_id', 'movie_name','year','kind'],engine='python', encoding='latin-1')\n",
    "\n",
    "    \n",
    "    merged_df = pd.merge(user_item_df, movie_info_df[['item_id', 'movie_name']], on='item_id', how='left')\n",
    "    \n",
    "    \n",
    "    merged_df.insert(0, 'index', range(1, len(merged_df) + 1))\n",
    "    \n",
    "    \n",
    "    final_df = merged_df[['index', 'item_id', 'movie_name']]\n",
    "    \n",
    "    \n",
    "    final_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "# Usage\n",
    "merge_files('MFgt_save_dict1.csv', 'itemnew-processed.csv', 'gt-match-output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5c8f0c-9d53-4b0a-bda5-23deea6599e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: merged_with_movie_name.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "movies_recommendations = pd.read_csv('movies_recommendations.csv')\n",
    "match_output = pd.read_csv('gt-match-output.csv')\n",
    "\n",
    "# Merge the files based on the 'Line Number' from movies_recommendations and 'index' from match_output\n",
    "merged_df = pd.merge(movies_recommendations, match_output[['index', 'movie_name']], how='left', left_on='Line Number', right_on='index')\n",
    "\n",
    "# Drop the extra 'index' column after the merge\n",
    "merged_df = merged_df.drop(columns=['index'])\n",
    "\n",
    "# Save the merged result to a new CSV file\n",
    "output_file = 'merged_with_movie_name.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd6a531-5479-4e3f-b811-1225fbee69fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: merged_with_match_column.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the merged CSV file\n",
    "merged_df = pd.read_csv('merged_with_movie_name.csv')\n",
    "\n",
    "# Function to check if the movie_name matches any of Movie1 to Movie5\n",
    "def check_match(row):\n",
    "    for i in range(1, 6):\n",
    "        if row['movie_name'] == row[f'Movie {i}']:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "# Apply the check_match function to each row and create a new column for the result\n",
    "merged_df['Match'] = merged_df.apply(check_match, axis=1)\n",
    "\n",
    "# Save the updated dataframe with the new column\n",
    "output_file_with_match = 'merged_with_match_column.csv'\n",
    "merged_df.to_csv(output_file_with_match, index=False)\n",
    "\n",
    "print(f\"CSV file created at: {output_file_with_match}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e158f7c-7ed5-413f-9bd5-69b4c034b76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged CSV file with the match column\n",
    "df = pd.read_csv('merged_with_match_column.csv')\n",
    "\n",
    "# Function to calculate Hit@n\n",
    "def calculate_hit(df, n):\n",
    "    return df['Match'].apply(lambda x: 1 if 0 < x <= n else 0).mean()\n",
    "\n",
    "# Function to calculate DCG@n and NDCG@n for each row\n",
    "def calculate_dcg(row, n):\n",
    "    match = row['Match']\n",
    "    if 0 < match <= n:  # if there's a match in the top n\n",
    "        return 1 / np.log2(match + 1)\n",
    "    return 0\n",
    "\n",
    "# Function to calculate NDCG@n\n",
    "def calculate_ndcg(df, n):\n",
    "    # Calculate DCG@n for each row\n",
    "    df[f'DCG@{n}'] = df.apply(lambda row: calculate_dcg(row, n), axis=1)\n",
    "    # Ideal DCG@n (IDCG@n) is always 1, since the best match is in the first position\n",
    "    idcg = 1 / np.log2(2)\n",
    "    # Calculate NDCG@n for each row\n",
    "    df[f'NDCG@{n}'] = df[f'DCG@{n}'] / idcg\n",
    "    return df[f'NDCG@{n}'].mean()\n",
    "\n",
    "# Calculate Hit@3 and NDCG@3\n",
    "hit_at_3 = calculate_hit(df, 3)\n",
    "ndcg_at_3 = calculate_ndcg(df, 3)\n",
    "\n",
    "# Calculate Hit@5 and NDCG@5\n",
    "hit_at_5 = calculate_hit(df, 5)\n",
    "ndcg_at_5 = calculate_ndcg(df, 5)\n",
    "\n",
    "# Scale factor\n",
    "scale_factor = 70 / 1777\n",
    "\n",
    "# Scaled results\n",
    "scaled_hit_at_3 = hit_at_3 * scale_factor\n",
    "scaled_ndcg_at_3 = ndcg_at_3 * scale_factor\n",
    "scaled_hit_at_5 = hit_at_5 * scale_factor\n",
    "scaled_ndcg_at_5 = ndcg_at_5 * scale_factor\n",
    "\n",
    "# Output the results\n",
    "print(f\"Hit@3: {hit_at_3}\")\n",
    "print(f\"NDCG@3: {ndcg_at_3}\")\n",
    "print(f\"Hit@5: {hit_at_5}\")\n",
    "print(f\"NDCG@5: {ndcg_at_5}\")\n",
    "\n",
    "print(\"\\n### Scaled Results (Multiplied by 70 / 1777) ###\")\n",
    "print(f\"Scaled Hit@3: {scaled_hit_at_3}\")\n",
    "print(f\"Scaled NDCG@3: {scaled_ndcg_at_3}\")\n",
    "print(f\"Scaled Hit@5: {scaled_hit_at_5}\")\n",
    "print(f\"Scaled NDCG@5: {scaled_ndcg_at_5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6c61c-adcf-4f8b-bebd-5031ed00ac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
